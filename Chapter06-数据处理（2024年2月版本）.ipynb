{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a605cc0",
   "metadata": {},
   "source": [
    "<center><h1>数据处理与分析</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6e926",
   "metadata": {},
   "source": [
    "# 数据处理与分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0a456",
   "metadata": {},
   "source": [
    "数据处理是数据价值链中最关键的步骤。再数据分析中的工作百分之七八十都在做数据处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b0462",
   "metadata": {},
   "source": [
    "* 数据处理  \n",
    "* 数据标准化  \n",
    "* 数据分析  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab75c7",
   "metadata": {},
   "source": [
    "# 6.1数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62508f6",
   "metadata": {},
   "source": [
    "在数据分析时，海量的原始数据中存在着大量不完整、不一致、有异常的数据，严重影响到数据分析的结果，所以进行数据处理就显得尤为重要。  \n",
    "数据处理就是处理缺失数据以及清除无意义的数据，如删除原始数据集中的<b>无关数据、重复数据，平滑噪声数据，处理缺失值、异常值</b>。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1ddb5",
   "metadata": {},
   "source": [
    "## 6.1.1异常值处理 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531e1fc",
   "metadata": {},
   "source": [
    "异常值处理包括重复值和缺失值的处理，尤其对缺失值的处理要谨慎。当数据量较大，并且在删除缺失值不影响结论时，可以删除；当数据量较少，删除后可能会影响数据分析的结果时，最好是对缺失值进行填充。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d8c10",
   "metadata": {},
   "source": [
    "### 1.重复值的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42485a",
   "metadata": {},
   "source": [
    "Python中的Pandas模块对重复数据去重步骤如下。  \n",
    "（1）利用DataFrame中的duplicated()函数返回一个布尔型的Series，显示是否有重复行，没有重复行显示为False，有重复行则从重复的第二条记录起，重复的均显示为True。  \n",
    "（2）利用DataFrame中的drop_duplicates()函数，返回一个移除了重复行的DataFrame。  \n",
    "（3）使用df[df.列名.duplicated()]显示重复值的行。  \n",
    "显示重复值duplicated()函数格式如下：  \n",
    "\n",
    "``` \n",
    "   duplicated(self, subset=None, keep='first')\n",
    "```\n",
    "\n",
    "其中参数解释如下:\n",
    "```\n",
    "    subset：用于识别重复的列标签或列标签序列，默认所有列标签。  \n",
    "    keep='first'：除了第一次出现外，其余相同的被标记为重复。  \n",
    "    keep='last'：除了最后一次出现外，其余相同的被标记为重复。  \n",
    "    keep=False：所有相同的都被标记为重复。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744a63e",
   "metadata": {},
   "source": [
    "&ensp;如果duplicated()函数和drop_duplicates()函数中没有设置参数，则这两个函数默认判断全部列；如果在这两个函数中加入了指定的属性名（列名），如frame.drop_duplicates(['state'])，则指定部分属性（state列）进行重复项的判断。   \n",
    "   \n",
    "&ensp;drop_duplicates()：把数据结构中，行相同的数据去除（保留其中的一行）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeccfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "df = DataFrame({'age':Series([26,85,64,85,85]),\n",
    "       'name':Series(['Jason','John','Jerry','Cd','John'])})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc880cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示重复行\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf16304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#先取反，再取布尔值真，即删除name的重复行\n",
    "df[~df.duplicated('name')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除age列中的重复行\n",
    "df.drop_duplicates('age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a152790",
   "metadata": {},
   "source": [
    "&ensp;&ensp;上面的df中索引为4的行属于索引为1的重复行，去重后重复行索引为4的行被删除。  \n",
    "&ensp;&ensp;~表示取反，本例中所有为True的值转为False，而False转化为True，再从布尔值里提取数据，即把为真的值提取出来，相当于将False（取反前为True的重复行）值删除。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ebd102",
   "metadata": {},
   "source": [
    "### 2.缺失值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54391198",
   "metadata": {},
   "source": [
    "从统计上说，缺失的数据可能会产生有偏估计，从而使样本数据不能很好地代表总体，而现实中绝大部分数据都包含缺失值，因此如何处理缺失值很重要。\n",
    "一般说来，缺失值的处理包括两个步骤，即缺失数据的<font color=\"blue\">识别</font>和缺失值<font color=\"blue\">处理</font>。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced303a",
   "metadata": {},
   "source": [
    "#### （1）缺失数据的识别。  \n",
    "Pandas使用浮点值NaN表示浮点和非浮点数组里的缺失数据，并使用.isnull()和.notnull()函数来判断缺失情况。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_excel\n",
    "df = read_excel(r'file/rz.xlsx',sheet_name='Sheet2')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac70605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e61aeb5",
   "metadata": {},
   "source": [
    "对于某列要显示其空值所在的行，如“数分”列df[df.数分.isnull()]。  \n",
    "要删除这个空值行，也可以使用df[～df.数分.isnull()]，～表示取反。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c516e4",
   "metadata": {},
   "source": [
    "#### （2）缺失数据的处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4197d",
   "metadata": {},
   "source": [
    "对于缺失数据的处理有数据补齐、删除对应行、不处理等方法。  \n",
    "<b>①dropna()</b>：对数据结构中有值为空的行进行删除。  \n",
    "删除数据中空值所对应的行。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF=df.dropna()\n",
    "newDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089cb0d",
   "metadata": {},
   "source": [
    "本例中有NaN值的第2行、第7行已经被删除了。也可以指定参数how='all'，表示只有行里的数据全部为空时才丢弃，如df.dropna(how='all')。如果想以同样的方式按列丢弃，可以传入axis=1，如df.dropna(how='all',axis=1)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075eab5c",
   "metadata": {},
   "source": [
    "<b>②df.fillna()</b>：用其他数值填充NaN。  \n",
    "有些时候空数据直接删除会影响分析的结果，这时可以对空数据进行填补，如使用数值或者任意字符替代缺失值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced11912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bba143",
   "metadata": {},
   "source": [
    "本例第2行、第7行的空用“？”替代了缺失值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5eb74d",
   "metadata": {},
   "source": [
    "<b>③df.fillna(method='pad')</b>：用前一个数据值替代NaN。  \n",
    "用前一个数据值替代当前的缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789aad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66dc7d",
   "metadata": {},
   "source": [
    "<b>④ df.fillna(method='bfill')</b> ：用后一个数据值替代NaN。  \n",
    "与pad相反，bfill表示用后一个数据代替NaN。可以用limit限制每列可以替代NaN的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f18080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='bfill')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c600009",
   "metadata": {},
   "source": [
    "<b>⑤df.fillna(df.mean())</b>：用平均数或者其他描述性统计量来代替NaN。  \n",
    "使用均值来填补空数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a96ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.fillna(df.mean()) # 此处教材可能有误\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83027b1f",
   "metadata": {},
   "source": [
    "“数分”列中有一个空值，9个数的均值为60.77777778，故以60.777778替代，“高代”列也一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0b3f3",
   "metadata": {},
   "source": [
    "<b>⑥df.fillna(df.mean()['开始列名':'终止列名'] )</b> 起止连续的多列进行均值填充。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67050f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.fillna(df.mean()[\"数分\":] ) # 此处教材可能有误\n",
    "df.fillna(df.loc[:,'数分':].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a40eb",
   "metadata": {},
   "source": [
    "<b>⑦df.fillna({'列名1':值1,'列名2':值2})</b>：可以传入一个字典，对不同的列填充不同的值。\n",
    "为不同的列填充不同的值来填补空数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e03b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({'数分':100,'高代':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9ccf9",
   "metadata": {},
   "source": [
    "“数分”列填充值为100，“高代”列填充值为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7deea",
   "metadata": {},
   "source": [
    "<b>⑧strip()</b>：清除字符型数据左右（首尾）指定的字符，默认为空格，中间的不清除。  \n",
    "删除字符串左右或首尾指定的空格。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2683c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "df = DataFrame({'age':Series([26,85,64,85,85]),\n",
    "             'name':Series(['     Ben','John ',\n",
    "              '    Jerry','John  ','John'])})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'].str.strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7709072",
   "metadata": {},
   "source": [
    "如果要删除右边的，则用df['name'].str.rstrip()，删除左边的，则用df['name'].str.lstrip()，默认为删除空格，也可以带参数，删除右边的“n”代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'].str.rstrip('n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e72a7",
   "metadata": {},
   "source": [
    "## 6.1.2数据抽取 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db48afa",
   "metadata": {},
   "source": [
    "### 1．字段提取（列）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f750227",
   "metadata": {},
   "source": [
    "抽出某列上指定位置的数据作为新的列。\n",
    "```\n",
    "slice(start,stop)\n",
    "●  start：开始位置。\n",
    "●  stop：结束位置。\n",
    "```\n",
    "  手机号码一般11位，如18603518513，前三位186为品牌（联通），中间四位0315表示地区区域（太原），后四位8513才是手机号码。下面把手机号码数据分别进行抽取。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_excel\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet4')\n",
    "df.head()        #展示数据表的前5行，显示后5行为df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['电话']=df['电话'].astype(str)  #astype()转化类型\n",
    "df['电话']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee47ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#抽取手机号码的中间四位，以判断号码的地域\n",
    "areas= df['电话'].str.slice(3,7)\n",
    "areas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a3c24",
   "metadata": {},
   "source": [
    "### 2．字段拆分（行）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b141f99",
   "metadata": {},
   "source": [
    "按指定的字符sep，拆分已有的字符串。  \n",
    "<b>split(sep,n,expand=False) </b>  \n",
    "```\n",
    "sep：用于分隔字符串的分隔符。\n",
    "n：分隔后新增的列数。\n",
    "expand：是否展开为数据框，默认为False。\n",
    "```\n",
    "返回值：expand为True，返回DaraFrame；expand为False，返回Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_excel\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet4')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4124591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用Series的str属性的strip方法删除首位空格\n",
    "df['IP'].str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be711df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按第一个\".\"分成两列，1表示新增列数\n",
    "newDF= df[\"IP\"].str.split(\".\", n=1, expand=True)\n",
    "newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#给第一、二列增加列名称\n",
    "newDF.columns = ['IP1','IP2-4'] \n",
    "newDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85a5f6",
   "metadata": {},
   "source": [
    "### 3．记录抽取（行）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea7641",
   "metadata": {},
   "source": [
    "记录抽取是指根据一定的条件，对数据进行抽取。 \n",
    "\n",
    "> <font  color='blue'>dataframe[condition]</font>  \n",
    ">       condition：过滤条件。  \n",
    "\n",
    "返回值为DataFrame。    \n",
    "常用的condition类型如下。    \n",
    "```\n",
    "●  比较运算：==、<、>、>=、<=、!=，如df[df.comments>10000)]。\n",
    "●  范围运算：between(left,right)，如df[df.comments.between(1000,10000)]。\n",
    "●  空置运算：pandas.isnull(column) ，如df[df.title.isnull()]。\n",
    "●  字符匹配：str.contains(patten,na = False) ，如df[df.title.str.contains('电台',na=False)]。\n",
    "●  逻辑运算：&（与）、|（或）、not（取反），如df[(df.comments>=1000)&(df.comments<=10000)]与df[df.comments.between(1000,10000)]等价。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44d9ae",
   "metadata": {},
   "source": [
    "#### （1）按条件抽取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec125e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import read_excel\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet4')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.电话==13322252452]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.电话>13500000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.电话.between(13400000000,13999999999)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83869582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.IP.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.IP.str.contains('222.',na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea141522",
   "metadata": {},
   "source": [
    "#### （2）通过逻辑指针进行数据切片：df[逻辑条件]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "df =read_excel(r'file/i_nuc.xls',sheet_name='Sheet4')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5234e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.电话 >= 18822256753]   #单个逻辑条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.电话>=13422259938 )&(df.电话 < 13822254373)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4f4a3",
   "metadata": {},
   "source": [
    "### 4．按索引条件抽取（行）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517a6d9",
   "metadata": {},
   "source": [
    "#### （1）使用索引名（标签）选取数据："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de43dda",
   "metadata": {},
   "source": [
    "> df.loc[行标签,列标签]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_index('学号')   #更改“学号”列为新的索引\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[2308024241:2308024201] #选取a到b行的数据：df.loc['a':'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'电话'].head()         #选取“电话”列的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553c8d1",
   "metadata": {},
   "source": [
    "df.loc的第一个参数是行标签，第二个参数为列标签（可选参数，默认为所有列标签）。两个参数既可以是列表，也可以是单个字符。如果两个参数都为列表，则返回的是DataFrame，否则为Series。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': ['a', 'b', 'c'],'c': [\"A\",\"B\",\"C\"]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c012914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]     #抽取index=1的行，但返回的是Series，而不是DaTa Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[1,2]] #抽取index=1和2的两行 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00533066",
   "metadata": {},
   "source": [
    "```\n",
    "注意：当同时抽取多行时，行的索引必须是列表的形式，而不能是简单的逗号分隔，如\n",
    "df.loc[1,2]会提示出错。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77757fd9",
   "metadata": {},
   "source": [
    "#### （2）使用索引号选取数据：df.iloc[行索引号,列索引号]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e01a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet4')\n",
    "df=df.set_index('学号')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,0]       #选取第2行、第1列的值，返回的是单个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0,2],:]   #选取第1行和第3行的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:2,:]     #选取第1行到第3行(不包含第3行)的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1] #选取所有记录的第2列的值，返回的是一个Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,:]       #选取第2行数据，返回的为一个Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2237a0",
   "metadata": {},
   "source": [
    "说明：loc为location的缩写，iloc为integer & location的缩写。  \n",
    "&ensp;loc：<font color='blue'>通过索引抽取行数据。</font>  \n",
    "&ensp;iloc：<font color='blue'>通过索引号抽取行数据。 </font>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61faaf",
   "metadata": {},
   "source": [
    "### 5．随机抽样（行）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f760739",
   "metadata": {},
   "source": [
    "随机抽样是指随机从数据中按照一定的行数或者比例抽取数据。  \n",
    "随机抽样函数格式如下。  \n",
    "&ensp;&ensp;<font color=\"blue\">numpy.random.randint(start,end,num)</font>  \n",
    "start：范围的开始值。  \n",
    "end：范围的结束值。  \n",
    "num：抽样个数。  \n",
    "返回值：行的索引值序列。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet4')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(0,10,3)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[r,:]   #抽取r行数据，也可以直接写成df.loc[r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558fa806",
   "metadata": {},
   "source": [
    "### 6．字典数据（创建数据框）\n",
    "将字典数据抽取为dataframe有3种方法。\n",
    "#### （1）字典的key和value各作为一列。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee797787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import DataFrame\n",
    "\n",
    "d1={'a':'[1,2,3]','b':'[0,1,2]'}\n",
    "a1=pandas.DataFrame.from_dict(d1, orient='index') \n",
    "                  #将字典转为dataframe，并且key列作为index\n",
    "a1.index.name = 'key'    #将index的列名改成“key”\n",
    "b1=a1.reset_index()     #重新增加index，原index作为\"key\"列\n",
    "b1.columns=['key','value'] #对列重新命名为“key”和“value”\n",
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217c0b7",
   "metadata": {},
   "source": [
    "#### （2）字典里的每一个元素作为一列（同长）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2={'a':[1,2,3],'b':[4,5,6]}    #字典的value必须长度相等\n",
    "a2= DataFrame(d2)\n",
    "a2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04df73",
   "metadata": {},
   "source": [
    "#### （3）字典里的每一个元素作为一列（不同长）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'one' : pandas.Series([1, 2, 3]),'two' : pandas.Series([1, 2, 3, 4])} #字典的value长度可以不相等\n",
    "df = pandas.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1c808",
   "metadata": {},
   "source": [
    "## 6.1.3 插入记录（行）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bc77c",
   "metadata": {},
   "source": [
    "Pandas里并没有直接指定索引的插入行的方法，所以要自行设置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':[1, 2, 3], 'b':['a','b','c'],'c':[\"A\",\"B\",\"C\"]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = pd.DataFrame({df.columns[0]:\"--\", \n",
    "                             df.columns[1]:\"--\", \n",
    "                             df.columns[2]:\"--\"},\n",
    "                             index=[1]) #抽取df的index=1的行，\n",
    "                         #并将此行第一列columns[0]赋值“--”，第二列、第三列同样赋值“--”\n",
    "line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.concat([df.loc[:0],line,df.loc[1:]])\n",
    "df0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839134d",
   "metadata": {},
   "source": [
    "df.loc[:0]这里不能写成df.loc[0]，因为df.loc[0]表示抽取index=0的行，返回的是Series，而不是DataFrame。\n",
    "df0的索引没有重新给出新的索引，需要对索引重新进行设定。\n",
    "&ensp;  \n",
    "&ensp;  \n",
    "其方法有三：  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f8fca",
   "metadata": {},
   "source": [
    "<b>方法1</b>  \n",
    "先利用reset_index()函数给出新的索引，原索引将作为新增加的列“index”，再对新增加的列利用drop()删除新增的“index”列。此方法虽然有点烦琐，但有时确实有输出原索引的需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df0.reset_index()  #重新给出索引，后面详细解释\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43523a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.drop('index', axis=1)  #删除“index”列\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbd499",
   "metadata": {},
   "source": [
    "<b>方法2</b>   \n",
    "直接对reset_index()函数添加drop=True参数，即删除了原索引并给出新的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bafd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.concat([df.loc[:0],line,df.loc[1:]]).reset_index(drop=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106d361",
   "metadata": {},
   "source": [
    "<b>方法3</b>  \n",
    "先找出df0的索引长度lenth=len(df0.index)，再利用整数序列函数生成索引range(lenth)，然后把生成的索引赋值给df0.index。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.index=range(len(df0.index))\n",
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c386c",
   "metadata": {},
   "source": [
    "## 6.1.4 修改记录（列）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d51c5",
   "metadata": {},
   "source": [
    "修改数据是常有的事情。例如，数据中有些需要整体替换，有些需要个别修改等。  \n",
    "整列、整行替换比较容易做到，如df['平时成绩']= score_2，这里score_2是将被填进去的数据列（可以是列表或者Serise）。  \n",
    "df数据框中可能各列都有“NaN”的情况，需要把空值整体替换成“0”，以便于计算，类似于Word软件中的“查找替换”（Ctrl+H组合键），具体示例如下。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd0f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "df = pd.read_excel(r'file/i_nuc.xls',sheet_name='Sheet3')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d280929",
   "metadata": {},
   "source": [
    "<b>（1）单值替换</b>  \n",
    "> df.replace('B', 'A')   #用A替换B，也可以用df.replace({'B': 'A’})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9193b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('作弊',0)    #用0替换“作弊”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5947b",
   "metadata": {},
   "source": [
    "<b>（2）指定列单值替换</b>  \n",
    "用0替换“体育”列中“作弊”：\n",
    "> df.replace({'体育':'作弊'},0)  \n",
    "\n",
    "用0替换“体育”列中的“作弊”和“军训”列中的“缺考”：\n",
    "> df.replace({'体育':'作弊','军训':'缺考'},0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'体育':'作弊'},0)     #用0替换“体育”列中“作弊”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd954a",
   "metadata": {},
   "source": [
    "<b>（1）多值替换</b>  \n",
    "用“陈龙”替换“成龙”，用“周毅”替换“周怡”：\n",
    "> df.replace(['成龙','周怡'],['陈龙','周毅'])  \n",
    "\n",
    " 还可以用下面两种方式，效果一致。   \n",
    "> df.replace({'成龙':'陈龙','周怡':'周毅'})  \n",
    "> df.replace({'成龙','周怡'},{'陈龙','周毅’})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'成龙':'陈龙','周怡':'周毅'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3448b0",
   "metadata": {},
   "source": [
    "## 6.1.5交换行或列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226da16",
   "metadata": {},
   "source": [
    "可以直接使用df.reindex()函数交换两行或两列。df.reindex()函数在后面章节将详细讲解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813118bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1, 2, 3],'b': ['a', 'b', 'c'],'c': [\"A\",\"B\",\"C\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "hang=[0,2,1]\n",
    "df.reindex(hang)          #交换行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lie=['a','c','b']\n",
    "df.reindex(columns=lie)    #交换列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b3e00",
   "metadata": {},
   "source": [
    "也可以使用下面的方法，尽管有点麻烦，但是个可行的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[0,2],:]=df.loc[[2,0],:].values   #交换第0、2行两行\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['b','a']] = df.loc[:,['a', 'b']].values     #交换两列\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40afb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=list(df.columns)  #提取列名并做成列表\n",
    "i=name.index(\"a\")      #提取a的index\n",
    "j=name.index(\"b\")      #提取b的index\n",
    "name[i],name[j]=name[j],name[i]       #交换a、b的位置\n",
    "\n",
    "df.columns=name    #将a、b交换位置后的list作为df的列名\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca63bd",
   "metadata": {},
   "source": [
    "有了交换两列的方法，那么插入列就方便了。例如，要在b、c两列之间插入d列。  \n",
    "（1）增加列df0['d']='新增的值'。  \n",
    "（2）交换c、d两列的值。  \n",
    "（3）交换c、d两列的列名。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d']=range(len(df.index)) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['c','d']]=df.loc[:,['d','c']].values\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = [\"b\",\"a\",\"d\",\"c\"]\n",
    "df.columns=col_name\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4636a8",
   "metadata": {},
   "source": [
    "## 6.1.6 索引排名（操作）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a17e2",
   "metadata": {},
   "source": [
    "<b>1.sort_index()重新排序</b>  \n",
    "Series的sort_index(ascending=True)方法可以对index进行排序操作，ascending参数用于控制升序（ascending=True）或降序（ascending=False），默认为升序。  \n",
    "在DataFrame上，sort_index(axis=0, by=None, ascending=True) 方法多了一个轴向的选择参数和一个by参数，by参数的作用是针对某一（些）列进行排序（不能对行使用by参数）。  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "df0={'Ohio':[0,6,3],'Texas':[7,4,1],'California':[2,8,5]}\n",
    "df=DataFrame(df0,index=['a','d','c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0289e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_index()  #默认按index升序排序，降序添加参数ascending=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3042fd",
   "metadata": {},
   "source": [
    "说明：现已弃用df.sort_index(by='Texas')对列进行排序。对列排序可以使用df.sort_values('Texas')方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92154e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['Ohio','Texas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27468aaf",
   "metadata": {},
   "source": [
    "在Pandas中，可以使用rank()函数来进行排名操作。  \n",
    "rank()函数可以用于为数据帧中的元素分配排名，并提供不同的排名策略，例如从小到大排名、从大到小排名等。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dad911",
   "metadata": {},
   "source": [
    "Series.rank(method='average', ascending=True) 排名与排序的不同之处在于它会把对象的values替换成名次（从1到n），对于平级项可以通过方法里的method参数来处理，method参数有4个可选项：\n",
    "\n",
    "- average 相同值的元素将被分配平均排名。例如，如果有n个元素并列，那么它们的排名将是：并列首行所在的行数+0.5*(n-1)。\n",
    "- min 相同值的元素将被分配最低排名。例如，如果有n个元素并列，那么它们的排名将都是并列的第1行数据所在的行数。\n",
    "- max 相同值的元素将被分配最高排名。例如，如果有n个元素并列，那么它们的排名将都是最后一个元素所在的行数。\n",
    "- first 类似SQL中 row_number，根据出现顺序分配排名，首次出现的元素排名较高。排名等于行所在的行数。\n",
    "- dense 类似SQL中 dense_rank，根据出现顺序分配排名，但没有间隔。例如，如果有两个元素排名为1，下一个排名将为2，而不是3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132172a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "ser=Series([3,2,0,3],index=list('abcd'))\n",
    "# ser=Series([3,2,0,3])\n",
    "ser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9eaab",
   "metadata": {},
   "source": [
    "3 2 1 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.rank() # 3 + 0.5(2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36456344",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.rank(method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaa12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.rank(method='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355270c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.rank(method='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79968aa0",
   "metadata": {},
   "source": [
    "**注意：在 ser[0]和 ser[3]这对平级项上，不同 method 参数表现出不同的名次。数据框的\n",
    "rank(axis=0, method='average', ascending=True)方法多了一个 axis 参数，可选择按行\n",
    "或列分别进行排名**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a732e7",
   "metadata": {},
   "source": [
    "<b>2.reindex()重新索引</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e32c7",
   "metadata": {},
   "source": [
    "reindex() 顾名思义它的作用是用来重定义索引的，如果定义的索引没有匹配的数据，默认将已缺失值填充。而索引可以分 “行” 索引与 “列” 索引，所以reindex自然对于两者的修改都可以胜任。它在Series和DataFrame中都非常有用：  \n",
    "\n",
    "对于DataFrame，reindex() 可以修改行、列索引或者两个都修改。  \n",
    "\n",
    "对于Series，reindex() 会创建一个适应新索引的新对象，如果某个索引值当前不存在，就会引入缺失值。  \n",
    "\n",
    "另外，对于以上两个数据类型都可以通过fill_value参数填充默认值，也可以通过method参数设置填充方法。而method包含几个参数可以选择：  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42679827",
   "metadata": {},
   "source": [
    "- None (默认): 不做任何填充\n",
    "- pad / ffill: 用上一行的有效数据来填充。\n",
    "- backfill / bfill: 用下一行的有效数据来填充。\n",
    "- nearest: 用临近行的有效数据来填充。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eaeb3f",
   "metadata": {},
   "source": [
    "**Series**对象的重新索引通过reindex(index=None,\\*\\*kwargs) 方法实现。\\*\\*kwargs中常用的参数有两个，method=None和fill_value=np.NaN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "ser = Series([4.5,7.2,-5.3,3.6],index=['d','b','a','c'])\n",
    "A = ['a','b','c','d','e']\n",
    "ser.reindex(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088866af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = ser.reindex(A,fill_value=0)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser['b']=None\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.reindex(A,method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f720bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.reindex(A,fill_value=0,method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2a952",
   "metadata": {},
   "source": [
    "reindex()方法会返回一个新对象，其index严格遵循给出的参数，method:{'backfill', 'bfill', 'pad', 'ffill', None} 参数用于指定插值（填充）方式，当没有给出时，默认用fill_value填充，值为NaN（ffill = pad，bfill = back fill，分别指插值时向前还是向后取值）。  \n",
    "pad/ffill：用前一个非缺失值去填充该缺失值。  \n",
    "backfill/bfill：用下一个非缺失值填充该缺失值。  \n",
    "None：指定一个值去替换缺失值。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b040de4",
   "metadata": {},
   "source": [
    "**DataFrame**中，reindex()方法更多地不是修改DataFrame对象的索引，而只是修改索引的顺序，如果修改的索引不存在，就会使用默认的None代替此行，并且不会修改原数组，要修改，需要使用赋值语句。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(np.arange(9).reshape((3,3)),index=['a','d','c'],columns=['c1','c2','c3'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db66995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照给定的索引重新排序（索引）\n",
    "df_na=df.reindex(index=['a', 'c', 'b', 'd'])\n",
    "df_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对原来没有的新产生的索引行按给定的method方式赋值\n",
    "df_na.fillna(method='ffill',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b642f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对列按照给定列名索引重新排序（索引）\n",
    "states = ['c1', 'b2', 'c3']          \n",
    "df1=df.reindex(columns=states)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对原来没有的新产生的列名按给定的method方式赋值\n",
    "df1.fillna(method='ffill',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4be22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#也可对列按照给定列名索引重新排序（索引）并为新产生的列名赋值\n",
    "df2=df.reindex(columns=states,fill_value=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73fe86",
   "metadata": {},
   "source": [
    "<b>3.set_index()索引重置</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c58c78",
   "metadata": {},
   "source": [
    "前面重置索引讲过set_index()方法，可以对DataFrame重新设置某列为索引。  \n",
    "**DataFrame.set_index(keys, drop=True,append=False, inplace=False)**\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c31d4",
   "metadata": {},
   "source": [
    "set_index() 主要可以将数据表中指定的某列设置为索引或复合索引，如下是常涉及使用的几个参数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec515465",
   "metadata": {},
   "source": [
    "- keys：列标签或列标签/数组列表，需要设置为索引的列。\n",
    "- drop：默认为True，删除用作新索引的列，也就是当把某列设置为索引后，原来的列会移除。\n",
    "- append：是否将列附加到现有索引，默认为False。\n",
    "- inplace：输入布尔值，表示当前操作是否对原数据生效，默认为False。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355de29",
   "metadata": {},
   "source": [
    "**DataFrame通过set_index()方法不仅可以设置单索引，而且可以设置复合索引，打造层次化索引。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': ['a', 'b', 'c'],'c': [\"A\",\"B\",\"C\"]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e66603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['b','c'],drop=False,   append=True,  inplace=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aca1e3",
   "metadata": {},
   "source": [
    "<b>4.reset_index()索引还原</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c922f",
   "metadata": {},
   "source": [
    "reset_index()可以还原索引，重新变为默认的整型索引, 即reset_index()是set_index()的“逆运算”。  \n",
    "\n",
    "**df.reset_index(level=None, drop=False, inplace=False, col_level=0, col_fill=”)**   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9c866",
   "metadata": {},
   "source": [
    "如下是常涉及使用的几个参数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d932c",
   "metadata": {},
   "source": [
    "- level：数值类型可以为：int、str、tuple或list，默认无，仅从索引中删除给定级别。默认情况下移除所有级别。控制了具体要还原的那个等级的索引 。\n",
    "- drop：当指定drop=False（默认为False）时，则索引列会被还原为普通列；否则，如设置为True，原索引列被会丢弃。\n",
    "- inplace：输入布尔值，表示当前操作是否对原数据生效，默认为False。\n",
    "- col_level：int or str, default=0。如果列有多个级别，则确定将标签插入到哪个级别。默认情况下，它将插入到第一层。\n",
    "- col_fill：object, default。如果列有多个级别，则确定其他级别的命名方式。如果没有，则复制索引名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': ['a', 'b', 'c'],'c': [\"A\",\"B\",\"C\"]})\n",
    "df1=df.set_index(['b','c'],drop=False, append=True, inplace=False)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(level='b', drop=True, inplace=False, col_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2cfe9",
   "metadata": {},
   "source": [
    "## 6.1.7 数据合并与分组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd8a815",
   "metadata": {},
   "source": [
    "<b>1．记录合并（行）</b>   \n",
    "记录合并是指两个结构相同的数据框合并成一个数据框，也就是在一个数据框中追加另一个数据框的数据记录。\n",
    "```\n",
    "concat([dataFrame1, dataFrame2,…])\n",
    "●  DataFrame1：数据框。\n",
    "●  DataFrame2：数据框。\n",
    "返回值：DataFrame。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "df1 = read_excel(r'file/i_nuc.xls',sheet_name='Sheet3')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = read_excel(r'file/i_nuc.xls',sheet_name='Sheet5')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.concat([df1,df2])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609cf2ec",
   "metadata": {},
   "source": [
    "两个数据框的数据记录都合并到一起，实现了数据记录的追加，但是记录的索引并没有顺延，仍然保持着原有的状态。前面讲过合并两个数据框的append方法，再复习一下。\n",
    "> df.append(df2, ignore_index=True)              #把df2追加到df上，index直接顺延\n",
    "\n",
    "这里方法同样加一个ignore_index=True参数即可。\n",
    "> pandas.concat([df1,df2] ,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c422f8",
   "metadata": {},
   "source": [
    "<b>2．字段合并（列）</b>\n",
    "```\n",
    "字段合并是指将同一个数据框中的不同的列进行合并，形成新的列。\n",
    "X = x1+x2+…\n",
    "●  x1：数据列1。\n",
    "●  x2：数据列2。\n",
    "返回值：Series。合并前的序列，要求合并的序列长度一致。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame({'band':[189,135,134,133],\n",
    "         'area':['0351','0352','0354','0341'],\n",
    "         'num':[2190,8513,8080,7890]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(str)\n",
    "tel=df['band']+df['area']+df['num']\n",
    "tel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7417fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tel']=tel\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd3038",
   "metadata": {},
   "source": [
    "<b>3．字段匹配</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291b0e5",
   "metadata": {},
   "source": [
    "字段匹配是指不同结构的数据框（两个或以上的数据框），按照一定的条件进行匹配合并，即追加列，类似于Excel中的VLOOKUP函数。例如，有两个数据表，第一个表中有学号、姓名，第二个表中有学号、手机号，现需要整理一份数据表包含学号、姓名、手机号码，此时就需要用到merge()函数。  \n",
    "```\n",
    "merge(x,y,left_on,right_on) \n",
    "●  x：第一个数据框。\n",
    "●  y：第二个数据框。\n",
    "●  left_on：第一个数据框的用于匹配的列。\n",
    "●  right_on：第二个数据框的用于匹配的列。\n",
    "返回值：DataFrame。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f674780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "df1= pd.read_excel(r'file/i_nuc.xls',sheet_name ='Sheet3')\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.read_excel(r'file/i_nuc.xls',sheet_name ='Sheet4')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa7bd6",
   "metadata": {},
   "source": [
    "这里匹配了有相同学号的行，对于df1中有重复记录的，df2也对df1进行了重复的匹配。但假如第一个数据框df1中有“学号=2308024200”，第二个数据框df2中没有“学号=2308024200”，则在结果中不会有“学号=2308024200”的记录。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b786ea6",
   "metadata": {},
   "source": [
    "```\n",
    "merge()还有以下参数。  \n",
    "●  how：连接方式，包括inner（默认，取交集）、outer（取并集）、left（左侧DataFrame取全部）、right（右侧DataFrame取全部）。  \n",
    "●  on：用于连接的列名，必须同时存在于左右两个DataFrame对象中，如果未指定，则以left和right列名的交集作为连接键。如果左右侧DataFrame的连接键列名不一致，但是取值有重叠，就要用到上面示例的方法，使用left_on、right_on来指定左右连接键（列名）。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'key':['b','b','a','c','a','a','b'],'data1': range(7)})\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8faab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'key':['a','b','d'],'data2':range(3)})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2,on = 'key',how = 'right') #右连接，右侧DataFrame取全部，左侧DataFrame取部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2,on = 'key',how = 'outer')#外连接，取并集，并用nan填充"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b612ca4",
   "metadata": {},
   "source": [
    "<b>4．数据分组</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc0e28",
   "metadata": {},
   "source": [
    "根据数据分析对象的特征，按照一定的数据指标，把数据划分为不同的区间来进行研究，以揭示其内在的联系和规律性。简单来说，就是新增一列，将原来的数据按照其性质归入新的类别中  \n",
    "**cut(series,bins,right=True,labels=NULL)**\n",
    "\n",
    "- series：需要分组的数据。\n",
    "-  bins：分组的依据数据。\n",
    "-  right：分组的时候右边是否闭合。\n",
    "- labels：分组的自定义标签，可以不自定义   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c706ec",
   "metadata": {},
   "source": [
    "现有数据如图所示，将数据进行分组。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921b469",
   "metadata": {},
   "source": [
    "<img src=\"image/Chapter6_1.png\"  width=\"800\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a6e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "import pandas as pd\n",
    "df = pd.read_excel(r'file/rz.xlsx')\n",
    "df.head()     #查看前5行数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f24dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape     #查看数据df的“形状”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b687de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[min(df.解几)-1,60,70,80,max(df.解几)+1] \n",
    "lab=[\"不及格\",\"及格\",\"良好\",\"优秀\"]\n",
    "demo=pd.cut(df.解几,bins,right=False,labels=lab)\n",
    "demo.head()    #仅显示前5行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['demo']=demo\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287d94e",
   "metadata": {},
   "source": [
    "bins的取值应采用最大值的取法，即max(df.解几)+1中要有一个大于前一个数（80），否则会提示出错。例如，本例中最大的分值为84，若设置bins为bins=[min(df.解几)-1,60,70,80,90，max(df.解几)+1]，则“不及格”“及格”“中等”“良好”“优秀”都齐了，但是会报错，因为最后一项“max(df.解几)+1”其实等于84+1，也就是85，比前一项90小，这不符合单调递增原则，所以这种情况，最好先把最大值和最小值求出来，再分段。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1377417",
   "metadata": {},
   "source": [
    "## 6.1.8 数据运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08721b98",
   "metadata": {},
   "source": [
    "通过对各字段进行加、减、乘、除四则算术运算，计算出的结果作为新的字段，如图所示。\n",
    "<img src=\"image/Chapter6_2.png\"  width=\"800\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet3')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jj=df['解几'].astype(int)   \n",
    "jj=df['解几'].astype(\"Int64\")   #将df中的“解几”转化为int类型\n",
    "# gd=df['高代'].astype(int)\n",
    "gd=df['高代'].astype(\"Int64\")\n",
    "df['高代+解几']=jj+gd       #在df中新增“高代+解几”列，值为jj+gd\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370827f2",
   "metadata": {},
   "source": [
    "## 6.1.9 日期处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc7790",
   "metadata": {},
   "source": [
    "<b>1．日期转换</b>\n",
    "日期转换是指将字符型的日期格式转换为日期格式数据的过程。\n",
    "> to_datetime(dateString, format)\n",
    "```\n",
    "format格式表示内容如下。\n",
    "\n",
    "●  %Y：年份。\n",
    "●  %m：月份。\n",
    "●  %d：日期。\n",
    "●  %H：小时。\n",
    "●  %M：分钟。\n",
    "●  %S：秒。\n",
    "\n",
    "```\n",
    "例如，to_datetime(df.注册时间,format='%Y/%m/%d')。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d8d8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>159</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2016/3/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>753</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2016/3/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125</td>\n",
       "      <td>456</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2016/3/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>852</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2016/3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>210</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>2016/3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>115</td>\n",
       "      <td>299</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2016/3/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102</td>\n",
       "      <td>699</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>2016/3/7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201</td>\n",
       "      <td>599</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>2016/3/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>154</td>\n",
       "      <td>199</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016/3/9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>899</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2016/3/10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num  price  year  month       date\n",
       "0  123    159  2016      1   2016/3/1\n",
       "1  124    753  2016      2   2016/3/2\n",
       "2  125    456  2016      3   2016/3/3\n",
       "3  126    852  2016      4   2016/3/4\n",
       "4  127    210  2016      5   2016/3/5\n",
       "5  115    299  2016      6   2016/3/6\n",
       "6  102    699  2016      7   2016/3/7\n",
       "7  201    599  2016      8   2016/3/8\n",
       "8  154    199  2016      9   2016/3/9\n",
       "9  142    899  2016     10  2016/3/10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_excel\n",
    "from pandas import to_datetime\n",
    "df = read_excel(r'file/rz.xlsx', sheet_name ='Sheet6')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6313d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2016-03-01\n",
       "1   2016-03-02\n",
       "2   2016-03-03\n",
       "3   2016-03-04\n",
       "4   2016-03-05\n",
       "5   2016-03-06\n",
       "6   2016-03-07\n",
       "7   2016-03-08\n",
       "8   2016-03-09\n",
       "9   2016-03-10\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt = to_datetime(df.date,format=\"%Y/%m/%d\")\n",
    "df_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d718f",
   "metadata": {},
   "source": [
    "<b>2．日期格式化</b>  \n",
    "日期格式化是指将日期型的数据按照给定的格式转化为字符型的数据。\n",
    "> apply(lambda x:处理逻辑)   \n",
    ">datetime.strftime(x,format)\n",
    "\n",
    "例如，将日期型数据转化为字符型数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2569d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016/03/01\n",
       "1    2016/03/02\n",
       "2    2016/03/03\n",
       "3    2016/03/04\n",
       "4    2016/03/05\n",
       "5    2016/03/06\n",
       "6    2016/03/07\n",
       "7    2016/03/08\n",
       "8    2016/03/09\n",
       "9    2016/03/10\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_excel\n",
    "from pandas import to_datetime\n",
    "from datetime import datetime\n",
    "\n",
    "df = read_excel(r'file/rz.xlsx', sheet_name ='Sheet6')\n",
    "df_dt = to_datetime(df.date,format=\"%Y/%m/%d\")\n",
    "\n",
    "df_dt_str=df_dt.apply(lambda x: datetime.strftime(x,\"%Y/%m/%d\"))  \n",
    " #apply见后注\n",
    "df_dt_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13919f",
   "metadata": {},
   "source": [
    "注意：当希望将函数f应用到DataFrame对象的行或列时，可以使用.apply(f, axis=0, args=(), **kwds) 方法，axis=0表示按列运算，axis=1时表示按行运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40d0da2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ohio</th>\n",
       "      <th>texas</th>\n",
       "      <th>california</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ohio  texas  california\n",
       "a     1      1           2\n",
       "c     3      4           5\n",
       "d     6      5           8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df=DataFrame({'ohio':[1,3,6],'texas':[1,4,5],\n",
    "              'california':[2,5,8]}, index= ['a','c','d'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c4f547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ohio          5\n",
       "texas         4\n",
       "california    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x:x.max()-x.min()\n",
    "df.apply(f)  #默认按列运算，同df.apply(f,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ccfb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "c    2\n",
       "d    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(f,axis=1)  #按行运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c12aa",
   "metadata": {},
   "source": [
    "<b>3．日期抽取</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b5794",
   "metadata": {},
   "source": [
    "日期抽取是指从日期格式里面抽取出需要的部分属性。  \n",
    "<font  color='blue'>Data_dt.dt.property</font>\n",
    "```\n",
    "●  second：1～60秒，从1开始到60。\n",
    "●  minute：1～60分，从1开始到60。\n",
    "●  hour：1～24小时，从1开始到24。\n",
    "●  day：1～31日，一个月中第几天，从1开始到31。\n",
    "●  month：1～12月，从1开始到12。\n",
    "●  year：年份。\n",
    "●  weekday：1～7，一周中的第几天，从1开始，最大为7。\n",
    "```\n",
    "例如，对日期进行抽取。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8164e046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>159</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2016/3/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>753</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2016/3/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125</td>\n",
       "      <td>456</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2016/3/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>852</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2016/3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>210</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>2016/3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>115</td>\n",
       "      <td>299</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2016/3/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102</td>\n",
       "      <td>699</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>2016/3/7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201</td>\n",
       "      <td>599</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>2016/3/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>154</td>\n",
       "      <td>199</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016/3/9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>899</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2016/3/10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num  price  year  month       date\n",
       "0  123    159  2016      1   2016/3/1\n",
       "1  124    753  2016      2   2016/3/2\n",
       "2  125    456  2016      3   2016/3/3\n",
       "3  126    852  2016      4   2016/3/4\n",
       "4  127    210  2016      5   2016/3/5\n",
       "5  115    299  2016      6   2016/3/6\n",
       "6  102    699  2016      7   2016/3/7\n",
       "7  201    599  2016      8   2016/3/8\n",
       "8  154    199  2016      9   2016/3/9\n",
       "9  142    899  2016     10  2016/3/10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_excel\n",
    "from pandas import to_datetime\n",
    "df = read_excel(r'file/rz.xlsx', sheet_name ='Sheet6')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e3be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2016-03-01\n",
       "1   2016-03-02\n",
       "2   2016-03-03\n",
       "3   2016-03-04\n",
       "4   2016-03-05\n",
       "5   2016-03-06\n",
       "6   2016-03-07\n",
       "7   2016-03-08\n",
       "8   2016-03-09\n",
       "9   2016-03-10\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt =to_datetime(df.date,format='%Y/%m/%d')\n",
    "df_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7229a893",
   "metadata": {},
   "source": [
    "# 6.2 数据标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a523b",
   "metadata": {},
   "source": [
    "<b>1.min-max标准化</b>\n",
    "\n",
    "min-max标准化（Min-max Normalization），又名离差标准化，是对原始数据的线性变换，使结果映射到[0,1]区间且无量纲。公式如下。  \n",
    "```\n",
    "X*=(x-min)/(max-min)\n",
    "●  max：样本最大值。\n",
    "●  min：样本最小值。\n",
    "```\n",
    "当有新数据加入时需要重新进行数据归一化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e57a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学号</th>\n",
       "      <th>班级</th>\n",
       "      <th>姓名</th>\n",
       "      <th>性别</th>\n",
       "      <th>英语</th>\n",
       "      <th>体育</th>\n",
       "      <th>军训</th>\n",
       "      <th>数分</th>\n",
       "      <th>高代</th>\n",
       "      <th>解几</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2308024241</td>\n",
       "      <td>23080242</td>\n",
       "      <td>成龙</td>\n",
       "      <td>男</td>\n",
       "      <td>76</td>\n",
       "      <td>7.8</td>\n",
       "      <td>77</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2308024244</td>\n",
       "      <td>23080242</td>\n",
       "      <td>周怡</td>\n",
       "      <td>女</td>\n",
       "      <td>66</td>\n",
       "      <td>9.1</td>\n",
       "      <td>75</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2308024251</td>\n",
       "      <td>23080242</td>\n",
       "      <td>张波</td>\n",
       "      <td>男</td>\n",
       "      <td>85</td>\n",
       "      <td>8.1</td>\n",
       "      <td>75</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2308024249</td>\n",
       "      <td>23080242</td>\n",
       "      <td>朱浩</td>\n",
       "      <td>男</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>72.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2308024219</td>\n",
       "      <td>23080242</td>\n",
       "      <td>封印</td>\n",
       "      <td>女</td>\n",
       "      <td>73</td>\n",
       "      <td>8.8</td>\n",
       "      <td>92</td>\n",
       "      <td>61.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           学号        班级  姓名 性别  英语   体育  军训    数分    高代  解几\n",
       "0  2308024241  23080242  成龙  男  76  7.8  77  40.0  23.0  60\n",
       "1  2308024244  23080242  周怡  女  66  9.1  75  47.0  47.0  44\n",
       "2  2308024251  23080242  张波  男  85  8.1  75  45.0  45.0  60\n",
       "3  2308024249  23080242  朱浩  男  65    5  80  72.0  62.0  71\n",
       "4  2308024219  23080242  封印  女  73  8.8  92  61.0  47.0  46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_excel\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet3')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f29eb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1    0.184211\n",
       "2    0.131579\n",
       "3    0.842105\n",
       "4    0.552632\n",
       "Name: 数分, dtype: Float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale= (df.数分.astype(int)-df.数分.astype(int).min())/(df.数分.astype(int).max()-df.数分.astype(int).min())\n",
    "scale= (df.数分.astype(\"Int64\")-df.数分.astype(\"Int64\").min())/(df.数分.astype(\"Int64\").max()-df.数分.astype(\"Int64\").min())\n",
    "scale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d08dd",
   "metadata": {},
   "source": [
    "归一化还可以用如下方法。  \n",
    "对正项序列x1,x2,…,xn进行变换，得：  \n",
    "<img src=\"image/Chapter6_3.png\"  width=\"100\" height=\"100\">\n",
    "则新序列且y1,y2,…,yn[0,1]无量纲，并且显然有  \n",
    "<img src=\"image/Chapter6_4.png\"  width=\"100\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353c7d5",
   "metadata": {},
   "source": [
    "<b>2.Z-score标准化方法</b>\n",
    "   Z-score标准化方法给予原始数据的均值（Mean）和标准差（Standard Deviation），以进行数据的标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为：  \n",
    "> X*=(x-μ)/σ\n",
    "\n",
    "   其中μ为所有样本数据的均值，σ为所有样本数据的标准差。将数据按属性（按列进行）减去均值，并除以标准差，得到的结果是对于每个属性（每列）来说所有数据都聚集在0附近，标准差为1。\n",
    "\n",
    "\n",
    "   Z-score标准化方法适用于属性A的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。标准化后的变量值围绕0上下波动，大于0说明高于平均水平，小于0说明低于平均水平。  \n",
    "    使用sklearn.preprocessing.scale()函数可以直接对给定数据进行标准化。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eccf00",
   "metadata": {},
   "source": [
    "<img src=\"image/Chapter6_6.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90f2267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.45956454, -1.72222185, -1.93289119,  0.91114489, -0.24753647,\n",
       "        0.80581022, -0.24753647,  0.59514088,  0.1738022 , -0.35287114,\n",
       "        0.80581022, -0.35287114,  0.06846754, -0.24753647,  0.48980621,\n",
       "               nan, -0.03686713,  1.54315291,  0.59514088,  0.70047555,\n",
       "        0.91114489])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "df1=df['数分']\n",
    "df_scaled = preprocessing.scale(df1)\n",
    "df_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03255200",
   "metadata": {},
   "source": [
    "也可以使用sklearn.preprocessing.StandardScaler类，使用该类的好处在于可以保存训练集中的参数（均值、标准差），直接使用其对象转换测试集数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "670c7bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  2.],\n",
       "       [ 2.,  0.,  0.],\n",
       "       [ 0.,  1., -1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[ 1., -1.,  2.],[ 2.,  0.,  0.],[ 0.,  1., -1.]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87aa2057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1190905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.33333333])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_   #均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce3776b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81649658, 0.81649658, 1.24721913])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.scale_  #标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc26e00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.66666667, 1.55555556])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.var_  #方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2925bd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4078a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以直接使用训练集对测试集数据进行转换\n",
    "scaler.transform([[-1.,  1., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8a449",
   "metadata": {},
   "source": [
    "# 6.3 数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5307ec19",
   "metadata": {},
   "source": [
    "## 6.3.1 基本统计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0f989",
   "metadata": {},
   "source": [
    " &ensp;基本统计分析又叫描述性统计分析，一般统计某个变量的最小值、第一个四分位值、中值、第三个四分位值及最大值。   \n",
    "&ensp;描述性统计分析函数为describe()。返回值是均值、标准差、最大值、最小值、分位数等。括号中可以带一些参数，例如，percentitles=[0,2,0.4,0.6,0.8]就是指定只计算0.2、0.4、0.6、0.8分位数，而不是默认的1/4、1/2、3/4分位数。   \n",
    "&ensp;常用的统计函数如下。   \n",
    "```\n",
    "●  size：计数（此函数不需要括号）。\n",
    "●  sum()：求和。\n",
    "●  mean()：平均值。\n",
    "●  var()：方差。\n",
    "●  std()：标准差。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例6-1】数据的基本统计。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r'file/i_nuc.xls',sheet_name='Sheet7')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.数分.describe()   #查看“数分”列的基本统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()  #所有各列的基本统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.解几.size   #注意：这里没有括号()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e5b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.解几.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.解几.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.解几.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.解几.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.解几.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c716ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.解几.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fca596",
   "metadata": {},
   "source": [
    "Numpy数组可以使用mean()函数计算样本均值，也可以使用average()函数计算加权的样本均值。  \n",
    "计算“数分”的平均成绩，代码如下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(df['数分'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3126ed7",
   "metadata": {},
   "source": [
    "还可以使用average()函数，代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c27cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(df['数分'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c500fd",
   "metadata": {},
   "source": [
    "也可以使用pandas的DataFrame对象的mean()方法求均值，代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e67f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['数分'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35121f11",
   "metadata": {},
   "source": [
    "计算中位数，代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb78c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.median()\n",
    "df.iloc[:,5:].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013ff48",
   "metadata": {},
   "source": [
    "对于定性数据来说，众数是出现次数最多的值，使用mode()函数计算众数，代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff98660",
   "metadata": {},
   "source": [
    "## 6.3.2 分组分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab6c5f",
   "metadata": {},
   "source": [
    "&ensp;分组分析是指根据分组字段将分析对象划分成不同的部分，以进行对比分析各组之间的差异性的一种分析方法。  \n",
    "&ensp;常用的统计指标有计数、求和、平均值。    \n",
    "&ensp;常用形式如下。  \n",
    "> df.groupby( '分类')[ '被统计的列'].统计函数()  \n",
    "> df.groupby(by=['分类1','分类2',...])['被统计的列名'].agg([(统计别名1,统计函数1)，(统计别名2,统计函数2)，…])   \n",
    "```\n",
    "●  by：用于分组的列。\n",
    "●  [ ]：用于统计的列。\n",
    "●  .agg：统计别名显示统计值的名称，统计函数用于统计数据。\n",
    "size：计数\n",
    "sum：求和\n",
    "mean：均值\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6816e2",
   "metadata": {},
   "source": [
    "【例6-2】分组分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_excel\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet7')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby( '班级')[['军训','英语','体育', '性别']].mean()\n",
    "df.groupby( '班级')[['军训','英语','体育']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c832dca",
   "metadata": {},
   "source": [
    "groupby可将列名直接当作分组对象，分组中，数值列会被聚合，非数值列会从结果中排除，当by不止一个分组对象（列名）时，需要使用list。  \n",
    "> df.groupby(['班级', '性别'])[['军训','英语','体育']].mean() #by=可省略不写  \n",
    "\n",
    "当统计不止一个统计函数并用别名显示统计结果的名称时，比如要同时计算某列数据的mean、std、sum等，可以使用agg()函数，其参数为二元元组的形式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['班级','性别'])['军训'].agg([('总分',np.sum),\n",
    "                                                 ('人数',np.size),\n",
    "                                                 ('平均值',np.mean),\n",
    "                                                 ('方差',np.var),\n",
    "                                                 ('标准差',np.std),\n",
    "                                                 ('最高分',np.max),\n",
    "                                                 ('最低分',np.min)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b03def",
   "metadata": {},
   "source": [
    "## 6.3.3 分布分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b66c1",
   "metadata": {},
   "source": [
    "分布分析指根据分析的目的，将数据（定量数据）等距或不等距分组，进行研究各组分布规律的一种分析方法。  \n",
    "【例6-3】分布分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796961ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy \n",
    "from pandas import read_excel\n",
    "df = pd.read_excel(r'file/i_nuc.xls',sheet_name='Sheet7')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df1549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['总分']=df.英语+df.体育+df.军训+df.数分+df.高代+df.解几\n",
    "df['总分'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a81dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['总分'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [min(df.总分)-1,400,450,max(df.总分)+1]   #将数据分成三段\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['400及其以下','400到450','450及其以上']  #给三段数据贴标签\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "总分分层 = pd.cut(df.总分,bins,labels=labels)\n",
    "总分分层.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94545472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['总分分层']= 总分分层\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['总分分层']).agg({'总分':np.size}).rename(columns={\"总分\":'人数'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d691a1",
   "metadata": {},
   "source": [
    "## 6.3.4 交叉分析 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95f1bc8",
   "metadata": {},
   "source": [
    "交叉分析通常用于分析两个或两个以上分组变量之间的关系，以交叉表形式进行变量间关系的对比分析。一般分为：定量、定量分组交叉，定量、定性分组交叉，定性、定型分组交叉。\n",
    "```\n",
    "pivot_table(values,index,columns,aggfunc,fill_value)\n",
    "●  values：数据透视表中的值。\n",
    "●  index：数据透视表中的行。\n",
    "●  columns：数据透视表中的列。\n",
    "●  aggfunc：统计函数。\n",
    "●  fill_value：NA值的统一替换。\n",
    "```\n",
    "返回值：数据透视表的结果  \n",
    "【例6-4】利用上例的数据做交叉分析。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d44cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy \n",
    "from pandas import pivot_table \n",
    "from pandas import read_excel\n",
    "df = pd.read_excel(r'file/i_nuc.xls',sheet_name='Sheet7')\n",
    "# df.pivot_table(index=['班级','姓名'])\n",
    "df.pivot_table(index=['班级','姓名','性别'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7bacc",
   "metadata": {},
   "source": [
    "默认对所有的数据列进行透视，非数值列自动删除，也可选取部分列进行透视。\n",
    "> df.pivot_table(['军训','英语','体育', '性别'],index=['班级','姓名'])\n",
    "\n",
    "更复杂一点的透视表如下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['总分']=df.英语+df.体育+df.军训+df.数分+df.高代+df.解几\n",
    "bins = [min(df.总分)-1,400,450,max(df.总分)+1]  #将数据分成三段\n",
    "labels=['400及其以下','400到450','450及其以上'] #给三段数据贴标签\n",
    "总分分层 = pd.cut(df.总分,bins,labels=labels)\n",
    "df['总分分层']= 总分分层\n",
    "df.pivot_table(values=['总分'],\n",
    "           index=['总分分层'],\n",
    "           columns=['性别'],\n",
    "           aggfunc=[numpy.size,numpy.mean])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e366f6",
   "metadata": {},
   "source": [
    "## 6.3.5 结构分析 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d2616",
   "metadata": {},
   "source": [
    "结构分析是在分组以及交叉的基础上，计算各组成部分所占的比重，进而分析总体的内部特征的一种分析方法。  \n",
    "这个分组主要是指定性分组，定性分组一般看结构，它的重点在于占总体的比重。   \n",
    "我们经常把市场比作蛋糕，市场占有率就是一个经典的应用。另外，股权也是结构的一种，如果股票比率大于50%，那就有绝对的话语权。  \n",
    "axis参数说明：0表示列，1表示行。  \n",
    "【例6-5】结构分析。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "from pandas import pivot_table    #在spyder下也可以不导入\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name= 'Sheet7')\n",
    "df['总分']=df.英语+df.体育+df.军训+df.数分+df.高代+df.解几\n",
    "df_pt = df.pivot_table(values=['总分'],\n",
    "                  index=['班级'],columns=['性别'],aggfunc=[np.sum])\n",
    "df_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6120e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt.sum(axis=1)  #按列合计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt.div(df_pt.sum(axis=1),axis=0)  #按列占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17459c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt.div(df_pt.sum(axis=0),axis=1)  #按行占比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297bfe84",
   "metadata": {},
   "source": [
    "在第4个输出按列占比中23080242班级中女生成绩占比0.332193，男生成绩占比0.667807。其他班级数据同样，23080243班女生成绩占比0.487697，男生成绩占比0.512303；23080244班女生成绩占比0.239919，男生成绩占比0.760081。   \n",
    "在第5个输出女生成绩占比中，23080242班占比0.276218，23080243班占比0.429790，23080244班占比0.293992。  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21236c86",
   "metadata": {},
   "source": [
    "## 6.3.6 相关分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39a8a3",
   "metadata": {},
   "source": [
    "&ensp;判断两个变量是否具有线性相关关系的最直观的方法是直接绘制散点图，看变量之间是否符合某个变化规律。  \n",
    "&ensp;相关分析研究现象之间是否存在某种依存关系，并对具体有依存关系的现象探讨其相关方向以及相关程度，是研究随机变量之间的相关关系的一种统计方法。  \n",
    "&ensp;为了更加准确地描述变量之间的线性相关程度，通过计算相关系数来进行相关分析，在二元变量的相关分析过程中，比较常用的有Pearson相关系数、Spearman秩相关系数和判定系数。Pearson相关系数一般用于分析两个连续品变量之间的关系，要求连续变量的取值服从正态分布。不服从正态分布的变量、分类或等级变量之间的关联性可采用Spearman秩相关系数（也称等级相关系数）来描述。  \n",
    "&ensp;相关系数：可以用来描述定量变量之间的关系。   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c651d12",
   "metadata": {},
   "source": [
    "<h1 align='center'>相关系数</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4f68a4",
   "metadata": {},
   "source": [
    "<img src=\"image/Chapter6_5.png\"  width=\"800\" height=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037649b",
   "metadata": {},
   "source": [
    "相关分析函数如下。    \n",
    "<font color=\"blue\" font-weight=\"bold\">DataFrame.corr()</font>  \n",
    "<font color=\"blue\" font-weight=\"bold\">Series.corr(other)</font>  \n",
    "如果由DataFrame调用corr方法，那么将会计算每列两两之间的相似度。如果由序列调用corr方法，那么只计算该序列与传入的序列之间的相关度。  \n",
    "返回值：DataFrame调用，返回DataFrame；Series调用，返回一个数值型，大小为相关度。  \n",
    "【例6-6】相关分析。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "\n",
    "df = read_excel(r'file/i_nuc.xls',sheet_name='Sheet7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86395b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['高代'].corr(df['数分'])   #两列之间的相关度计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['英语','体育','军训','解几','数分','高代']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7866ec",
   "metadata": {},
   "source": [
    "第2个输出结果为0.6077，处在0.3和0.8之间，属于中度相关，比较符合实际，毕竟都属于数学类课程，但是又存在差异，不像高等代数和线性代数，应该是高度相关。   \n",
    "本章的数据清洗及分析操作方法请查阅附件B部分，附件B来源于网络。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c616f85",
   "metadata": {},
   "source": [
    "# 6.4 实战体验：股票统计分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494e593",
   "metadata": {},
   "source": [
    "本案例主要学习以下内容。  \n",
    "（1）获取股票数据。  \n",
    "（2）利用数学和统计分析函数完成实际统计分析应用。  \n",
    "（3）存储数据。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf10af",
   "metadata": {},
   "source": [
    "<h1>1．数据获取</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f2c92",
   "metadata": {},
   "source": [
    "Pandas库提供了专门从财经网站获取金融数据的API接口，该模块包含在pandas-datareader包中，因此导入模块时需要安装该包。通过Anaconda下的Anaconda Prompt执行下面的命令即可，如图所示。   \n",
    "> conda install pandas_datareader  \n",
    "\n",
    "或者  \n",
    "> pip install pandas_datareader  \n",
    "\n",
    "当调用该包时需导入下面的代码。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067784d7",
   "metadata": {},
   "source": [
    "> import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36caf18",
   "metadata": {},
   "source": [
    "DataReader可从多个金融网站获取到股票数据，如“yahoo”“iex”等。DataReader函数的第一个参数为股票代码，Bank of America的代码为“BAC”，国内股市采用的输入方式为“股票代码”+“对应股市”，上证股票在股票代码后面加上“.SS”（如中国银行股票代码为601988.SS），深圳股票在股票代码后面加上“.SZ”。DataReader函数的第三、四个参数为股票数据的起止时间。返回的数据格式为DataFrame。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2eac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "start = datetime.datetime(2017,1,1)#获取数据的起始时间\n",
    "end = datetime.date.today()#获取数据的结束时间\n",
    "stock = web.DataReader(\"BAC\", \"yahoo\", start, end)#获取yahoo从2017年1月1日至今的BAC股票数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8119dc5",
   "metadata": {},
   "source": [
    "说明：由于接口的更改或网速的问题，可能无法获取数据，请更换上面代码中第一个参数股票代码（\"BAC\"）或者更换第二个参数数据来源（\"yahoo\"），或者直接从本书给定的数据源中下载数据：stock._data_bac.csv。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.head()#查看数据的前5行，默认是前5行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ced3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.tail(3)#查看数据的末3行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stock) #查看数据的长度（即条数）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf2353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.to_csv('stock_data_bac.csv ')#保存数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f9d19",
   "metadata": {},
   "source": [
    "此处是从yahoo获取的美国BAC银行的交易数据，包括Date（时间）、High（最高价）、Low（最低价）、Open（开盘价）、Close（收盘价）、Volume（成交量）、Adj Close（调整后的收盘价）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = dict(fname = \"file/stock_data_bac.csv\", #注意文件路径\n",
    "              delimiter = ',',\n",
    "              usecols = (4,5),\n",
    "              skiprows=1,\n",
    "              unpack = True)\n",
    "closePrice,volume = np.loadtxt(**params)\n",
    "print(closePrice)\n",
    "print(volume)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f130e11",
   "metadata": {},
   "source": [
    "```\n",
    "说明：numpy.loadtxt需要传入5个关键字参数。\n",
    "（1）fname：文件名（含路径）。\n",
    "（2）delimiter：分隔符，数据类型为字符串str。\n",
    "（3）usecols：读取的列数，数据类型为元组tuple,其中元素个数有多少个，则选出多少列。此处注意A列是第0列，B列才是第1列。\n",
    "（4）unpack：是否解包，数据类型为布尔bool。\n",
    "（5）skiprows：跳过前1行，默认值是0。如果设置skiprows=2，则会跳过前两行。\n",
    "（6）converters：对数据进行预处理的参数。converters是一个字典, 表示第n列（本例中后面为0列）使用函数来进行预处理。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21710f",
   "metadata": {},
   "source": [
    "<h1>2．数据分析</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25025585",
   "metadata": {},
   "source": [
    "要想知道股票的基本信息，需要计算出成交量加权平均价格、股价近期最高价的最大值和最低价的最小值、股价近期最高价和最低价的最大值和最小值的差值、收盘价的中位数、收盘价的方差，以及计算股票收益率、年波动率及月波动率。  \n",
    "### （1）计算成交量加权平均价格。  \n",
    "成交量加权平均价格（Volume-Weighted Average Price，VWAP）是一个非常重要的经济学量，代表着金融资产的“平均”价格。  \n",
    "某个价格的成交量越大，该价格所占的权重就越大。VWAP就是以成交量为权重计算出来的加权平均值。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = dict(fname = \"file/stock_data_bac.csv\",\n",
    "              delimiter = ',',\n",
    "              usecols = (4,5),\n",
    "              skiprows=1,\n",
    "              unpack = True)\n",
    "\n",
    "closePrice,volume = np.loadtxt(**params)\n",
    "print(\"没有加权均值:\",np.average(closePrice))\n",
    "print(\"含加权均值:\",np.average(closePrice,weights=volume))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2dfd25",
   "metadata": {},
   "source": [
    "从计算的结果可以看出以下几点。  \n",
    "① 对于numpy.average()方法，是否加权重weights，结果会有区别。  \n",
    "② 如果numpy.average()方法没有weights参数，则与numpy.mean方法效果相同。  \n",
    "③ np.mean(closePrice)和closePrice.mean()效果相同。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54662f1a",
   "metadata": {},
   "source": [
    "### （2）计算最大值和最小值。\n",
    "计算股价最高价的最大值和最低价的最小值使用numpy.max(highPrice)、numpy.min (lowPrice)或者highPrice.max()、lowPrice.min()方法均可。  \n",
    "最高价位于Excel中的第2列，最低价位于Excel中的第3列，所以usecols=(2,3)。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = dict(fname = \"file/stock_data_bac.csv\",\n",
    "              delimiter = ',',\n",
    "              usecols = (1,2),  \n",
    "              skiprows=1,\n",
    "              unpack = True)\n",
    "highPrice,lowPrice = np.loadtxt(**params)\n",
    "print(\"highPrice _max=\",highPrice.max())\n",
    "print(\"lowPrice _min=\",lowPrice.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479cffcb",
   "metadata": {},
   "source": [
    "### （3）计算极差。  \n",
    "计算股价最高价和最低价的最大值与最小值的差值，即极差，使用np.ptp(highPrice)、np.ptp(lowPrice)或highPrice.ptp()、lowPrice.ptp()方法均可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad460258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = dict(\n",
    "                fname = \"file/stock_data_bac.csv\",\n",
    "                delimiter = ',',\n",
    "                usecols = (1,2), \n",
    "                skiprows=1,\n",
    "                unpack = True)\n",
    "highPrice,lowPrice = np.loadtxt(**params)\n",
    "print(\"max - min of high price:\", highPrice.ptp())\n",
    "print(\"max - min of low price:\", lowPrice.ptp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069ee87",
   "metadata": {},
   "source": [
    "### （4）计算中位数。  \n",
    "计算收盘价的中位数可以使用np.median(closePrice)方法，但不能使用closePrice.median()方法，没有这个用法，在numpy中也没有直接计算众数的函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = dict(fname = \"file/stock_data_bac.csv\",\n",
    "              delimiter = ',',\n",
    "              usecols = 4,    \n",
    "              skiprows=1 )\n",
    "closeprice = np.loadtxt(**params)\n",
    "print(\"median =\",np.median(closePrice))\n",
    "median = 27.23925\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a257c43",
   "metadata": {},
   "source": [
    "中位数是指中间的那个数。当奇数个时则是取中间那个数，当偶数个时，则是中间两数的均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14d39b",
   "metadata": {},
   "source": [
    "### （5）计算方差。\n",
    "计算收盘价的方差使用closePrice.var()或者np.var(closePrice)方法，效果相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = dict(\n",
    "                 fname = \"file/stock_data_bac.csv\",\n",
    "                 delimiter = ',',\n",
    "                 usecols = 4,\n",
    "                 skiprows=1)\n",
    "closePrice = np.loadtxt(**params)\n",
    "print(\"variance =\",np.var(closePrice))\n",
    "print(\"variance =\",closePrice.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7255e6",
   "metadata": {},
   "source": [
    "### （6）计算股票收益率、年波动率及月波动率。  \n",
    "波动率在投资学中是对价格变动的一种度量，历史波动率可以根据历史价格数据计算得出。在计算历史波动率时，需要先求出对数收益率。在下面的代码中将求得的对数收益率赋值给logReturns  \n",
    "通常年交易日取252天，交易月取12个月。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f48bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "params = dict(fname = \"file/stock_data_bac.csv\",\n",
    "                 delimiter = ',',\n",
    "                 usecols = 4,\n",
    "                 skiprows=1)\n",
    "closePrice = np.loadtxt(**params)\n",
    "\n",
    "logReturns = np.diff(np.log(closePrice))\n",
    "annual_volatility = logReturns.std()/logReturns.mean()*np.sqrt(252)\n",
    "monthly_volatility = logReturns.std()/logReturns.mean()*np.sqrt(12)\n",
    "print(\"年波动率\",annual_volatility)\n",
    "print(\"月波动率\",monthly_volatility)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715c12c",
   "metadata": {},
   "source": [
    "np.diff()函数实现每行的后一个值减去前一行的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7f881",
   "metadata": {},
   "source": [
    "### （7）股票统计分析。  \n",
    "文件中的数据为给定时间范围内某股票的数据，现计算如下数据。  \n",
    "① 获取该时间范围内交易日星期一、星期二、星期三、星期四、星期五分别对应的平均收盘价。  \n",
    "② 平均收盘价最低、最高分别为星期几。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec82f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def dateStr2num(s):\n",
    "     s = s.decode(\"utf-8\")\n",
    "     return datetime.datetime.strptime(s, \"%Y-%m-%d\").weekday()\n",
    "\n",
    "params = dict(fname = \"file/stock_data_bac.csv\",\n",
    "                 delimiter = ',',\n",
    "                 usecols = (0,4),   \n",
    "                 skiprows=1,\n",
    "                 converters = {0:dateStr2num},\n",
    "                 unpack = True)\n",
    "\n",
    "date, closePrice = np.loadtxt(**params)\n",
    "average = []\n",
    "for i in range(5):\n",
    "     average.append(closePrice[date==i].mean())\n",
    "     print(\"星期%d的平均收盘价为:\" %(i+1), average[i])\n",
    "\n",
    "print(\"\\n平均收盘价最低是星期%d\" %(np.argmin(average)+1))#最小值坐标\n",
    "print(\"平均收盘价最高是星期%d\" %(np.argmax(average)+1)) #最大值坐标\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d45e2",
   "metadata": {},
   "source": [
    "说明：获取股票数据的模块较多，如tushare模块，tushare为了避免部分用户低门槛无限制地恶意调用数据，其tushare Pro接口开始引入积分制度，只有具备一定积分级别的用户才能调取相应的API。  \n",
    "获取token凭证码操作步骤为：注册新用户，从头像上单击用户名，打开个人主页，再单击页面“接口TOKEN”选项，最后复制图标即可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1219cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
