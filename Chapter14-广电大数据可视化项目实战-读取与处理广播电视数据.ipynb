{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d14a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4246720, 12) (154667, 6)\n"
     ]
    }
   ],
   "source": [
    "# 代码6-1\n",
    "import pandas as pd\n",
    "data_raw = pd.read_csv('file/media_index.csv', encoding='gbk', header='infer')\n",
    "payevents = pd.read_csv('file/mmconsume_payevents.csv', sep=',',\n",
    "                        encoding='gbk', header='infer')\n",
    "print(data_raw.shape, payevents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c65a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看过滤后的特殊线路的用户: [ 0. nan  5.  1.]\n",
      "查看过滤后的政企用户: ['HC级' 'HE级' 'HB级']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15720\\69133097.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  media1.end_time = pd.to_datetime(media1.end_time)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15720\\69133097.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  media1.origin_time = pd.to_datetime(media1.origin_time)\n"
     ]
    }
   ],
   "source": [
    "# 代码6-2\n",
    "media = pd.read_csv('file/media_index.csv', encoding='gbk', header='infer')\n",
    "# 将“-高清”替换为空\n",
    "media['station_name'] = media['station_name'].str.replace('-高清', '')\n",
    "# 过滤特殊线路、政企用户\n",
    "media = media.loc[(media.owner_code != 2)&(media.owner_code != 9)&\n",
    "                 (media.owner_code != 10), :]\n",
    "print('查看过滤后的特殊线路的用户:', media.owner_code.unique())\n",
    "media = media.loc[(media.owner_name != 'EA级')&(media.owner_name != 'EB级')&\n",
    "                 (media.owner_name != 'EC级')&(media.owner_name != 'ED级')&\n",
    "                 (media.owner_name != 'EE级'), :]\n",
    "print('查看过滤后的政企用户:', media.owner_name.unique())\n",
    "\n",
    "# 对开始时间进行拆分\n",
    "# 检查数据类型\n",
    "type(media.loc[0, 'origin_time'])\n",
    "# 转化为时间类型\n",
    "media['end_time'] = pd.to_datetime(media['end_time'])\n",
    "media['origin_time'] = pd.to_datetime(media['origin_time'])\n",
    "# 提取秒\n",
    "media['origin_second'] = media['origin_time'].dt.second\n",
    "media['end_second'] = media['end_time'].dt.second\n",
    "# 筛选数据\n",
    "ind1 = (media['origin_second'] == 0) & (media['end_second'] == 0)\n",
    "media1 = media.loc[~ind1, :]\n",
    "\n",
    "# 基于开始时间和结束时间的记录去重\n",
    "media1.end_time = pd.to_datetime(media1.end_time)\n",
    "media1.origin_time = pd.to_datetime(media1.origin_time)\n",
    "media1 = media1.drop_duplicates(['origin_time', 'end_time'])\n",
    "\n",
    "# 隔夜处理\n",
    "# 去除开始时间，结束时间为空值的数据\n",
    "media1 = media1.loc[media1.origin_time.dropna().index, :]\n",
    "media1 = media1.loc[media1.end_time.dropna().index, :]\n",
    "# 创建星期特征列\n",
    "media1['星期'] = media1.origin_time.apply(lambda x: x.weekday()+1)\n",
    "dic = {1:'星期一', 2:'星期二', 3:'星期三', 4:'星期四', 5:'星期五', 6:'星期六', 7:'星期日'}\n",
    "for i in range(1, 8):\n",
    "    ind = media1.loc[media1['星期'] == i, :].index\n",
    "    media1.loc[ind, '星期'] = dic[i]\n",
    "# 查看有多少观看记录是隔天的，隔天的进行隔天处理\n",
    "a = media1.origin_time.apply(lambda x :x.day)\n",
    "b = media1.end_time.apply(lambda x :x.day)\n",
    "sum(a != b)\n",
    "media2 = media1.loc[a != b, :].copy()  # 需要做隔天处理的数据\n",
    "def geyechuli_xingqi(x):\n",
    "    dic = {'星期一':'星期二', '星期二':'星期三', '星期三':'星期四', '星期四':'星期五',\n",
    "           '星期五':'星期六', '星期六':'星期日', '星期日':'星期一'}\n",
    "    return x.apply(lambda y: dic[y.星期], axis=1)\n",
    "media1.loc[a != b, 'end_time'] = media1.loc[a != b, 'end_time'].apply(lambda x:\n",
    "    pd.to_datetime('%d-%d-%d 23:59:59'%(x.year, x.month, x.day)))\n",
    "media2.loc[:, 'origin_time'] = pd.to_datetime(media2.end_time.apply(lambda x:\n",
    "    '%d-%d-%d 00:00:01'%(x.year, x.month, x.day)))\n",
    "media2.loc[:, '星期'] = geyechuli_xingqi(media2)\n",
    "media3 = pd.concat([media1, media2])\n",
    "media3['origin_time1'] = media3.origin_time.apply(lambda x:\n",
    "    x.second + x.minute * 60 + x.hour * 3600)\n",
    "media3['end_time1'] = media3.end_time.apply(lambda x:\n",
    "    x.second + x.minute * 60 + x.hour * 3600)\n",
    "media3['wat_time'] = media3.end_time1 - media3.origin_time1  # 构建观看总时长特征\n",
    "\n",
    "# 清洗时长不符合的数据\n",
    "# 剔除下次观看的开始时间小于上一次观看的结束时间的记录\n",
    "media3 = media3.sort_values(['phone_no', 'origin_time'])\n",
    "media3 = media3.reset_index(drop=True)\n",
    "a = [media3.loc[i+1, 'origin_time'] < media3.loc[i, 'end_time'] for i in range(len(media3)-1)]\n",
    "a.append(False)\n",
    "aa = pd.Series(a)\n",
    "media3 = media3.loc[~aa, :]\n",
    "# 去除小于4S的记录\n",
    "media3 = media3.loc[media3['wat_time'] > 4, :]\n",
    "#  保存贴标签用\n",
    "media3.to_csv('file/media3.csv', na_rep='NaN', header=True, index=False)\n",
    "\n",
    "# 查看连续观看同一频道的时长是否大于3h\n",
    "# 发现这2000个用户不存在连续观看大于3h的情况\n",
    "media3['date'] = media3.end_time.apply(lambda x :x.date())\n",
    "media_group = media3['wat_time'].groupby([media3['phone_no'],\n",
    "                                         media3['date'],\n",
    "                                         media3['station_name']]).sum()\n",
    "media_group = media_group.reset_index()\n",
    "media_g = media_group.loc[media_group['wat_time'] >= 10800, ]\n",
    "media_g['time_label'] = 1\n",
    "o = pd.merge(media3, media_g, left_on=['phone_no', 'date', 'station_name'],\n",
    "             right_on=['phone_no', 'date', 'station_name'], how='left')\n",
    "oo = o.loc[o['time_label'] == 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码6-3\n",
    "payevents = pd.read_csv('file/mmconsume_payevents.csv', sep=',',\n",
    "                        encoding='gbk', header='infer')\n",
    "payevents.columns = ['phone_no', 'owner_name', 'event_time', 'payment_name',\n",
    "                     'login_group_name', 'owner_code']\n",
    "\n",
    "# 过滤特殊线路、政企用户\n",
    "payevents = payevents.loc[(payevents.owner_code != 2\n",
    "                          )&(payevents.owner_code != 9\n",
    "                          )&(payevents.owner_code != 10), :]  # 去除特殊线路数据\n",
    "print('查看过滤后的特殊线路的用户:', payevents.owner_code.unique())\n",
    "payevents = payevents.loc[(payevents.owner_name != 'EA级'\n",
    "                           )&(payevents.owner_name != 'EB级'\n",
    "                           )&(payevents.owner_name != 'EC级'\n",
    "                           )&(payevents.owner_name != 'ED级'\n",
    "                           )&(payevents.owner_name != 'EE级'), :]\n",
    "print('查看过滤后的政企用户：', payevents.owner_name.unique())\n",
    "payevents.to_csv('file/payevents2.csv', na_rep='NaN', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2b735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
